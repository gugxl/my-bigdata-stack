# ~/my-bigdata-stack/docker-compose.yml
version: "3.8"

networks:
  bigdata-net:
    driver: bridge

volumes:
  hadoop_namenode_data:
  hadoop_datanode_data:
  hadoop_historyserver_data:
  hbase_data:
  postgres_metastore_data:
  zookeeper_data:
  zookeeper_log:

services:
  # Builder service for the base image with OS dependencies
  base:
    image: my-bigdata-base:latest
    build:
      context: .
      dockerfile: ./services/base/Dockerfile

  # Builder service for the hadoop image
  hadoop-base:
    image: bigdata_hadoop-base:latest
    build:
      context: .
      dockerfile: ./services/hadoop-base/Dockerfile
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    depends_on:
      - base

  zookeeper:
    build:
      context: .
      dockerfile: ./services/zookeeper/Dockerfile
      args:
        ZOOKEEPER_VERSION: ${ZOOKEEPER_VERSION}
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - bigdata-net
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/data
      - zookeeper_log:/datalog
    environment:
      ZOO_SERVER_ID: 1

  postgres-metastore:
    image: postgres:14
    container_name: postgres-metastore
    hostname: postgres-metastore
    networks:
      - bigdata-net
    ports:
      - "5432:5432"
    volumes:
      - postgres_metastore_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

  namenode:
    image: bigdata_hadoop-base:latest
    depends_on:
      - hadoop-base
    container_name: namenode
    hostname: namenode
    command: ["hdfs", "namenode"]
    networks:
      - bigdata-net
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - ./configs/hadoop:/etc/hadoop
      - hadoop_namenode_data:/opt/hadoop/data/namenode
    environment:
      - HADOOP_USER_NAME=root
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  datanode:
    image: bigdata_hadoop-base:latest
    depends_on:
      namenode:
        condition: service_healthy
    container_name: datanode
    hostname: datanode
    command: ["hdfs", "datanode"]
    networks:
      - bigdata-net
    volumes:
      - ./configs/hadoop:/etc/hadoop
      - hadoop_datanode_data:/opt/hadoop/data/datanode

  resourcemanager:
    image: bigdata_hadoop-base:latest
    depends_on:
      - datanode
    container_name: resourcemanager
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    networks:
      - bigdata-net
    ports:
      - "8088:8088"
    volumes:
      - ./configs/hadoop:/etc/hadoop
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  nodemanager:
    image: bigdata_hadoop-base:latest
    depends_on:
      resourcemanager:
        condition: service_healthy
    container_name: nodemanager
    hostname: nodemanager
    command: ["yarn", "nodemanager"]
    networks:
      - bigdata-net
    volumes:
      - ./configs/hadoop:/etc/hadoop

  historyserver:
    image: bigdata_hadoop-base:latest
    depends_on:
      - resourcemanager
    container_name: historyserver
    hostname: historyserver
    command: ["mapred", "historyserver"]
    networks:
      - bigdata-net
    ports:
      - "19888:19888"
    volumes:
      - ./configs/hadoop:/etc/hadoop
      - hadoop_historyserver_data:/opt/hadoop/data/historyserver

  hbase-master:
    build:
      context: .
      dockerfile: ./services/hbase/Dockerfile
      args:
        HBASE_VERSION: ${HBASE_VERSION}
    depends_on:
      - namenode
      - zookeeper
      - base
    container_name: hbase-master
    hostname: hbase-master
    command: ["master", "start"]
    networks:
      - bigdata-net
    ports:
      - "16010:16010"
    volumes:
      - ./configs/hbase:/opt/hbase/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop
      - hbase_data:/data/hbase

  hbase-regionserver:
    build:
      context: .
      dockerfile: ./services/hbase/Dockerfile
      args:
        HBASE_VERSION: ${HBASE_VERSION}
    depends_on:
      - hbase-master
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    command: ["regionserver", "start"]
    networks:
      - bigdata-net
    volumes:
      - ./configs/hbase:/opt/hbase/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop

  hive-metastore:
    build:
      context: .
      dockerfile: ./services/hive/Dockerfile
      args:
        HIVE_VERSION: ${HIVE_VERSION}
        PG_JDBC_VERSION: ${PG_JDBC_VERSION}
    depends_on:
      - postgres-metastore
      - namenode
      - base
    container_name: hive-metastore
    hostname: hive-metastore
    command: ["metastore"]
    networks:
      - bigdata-net
    ports:
      - "9083:9083"
    volumes:
      - ./configs/hive:/opt/hive/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop

  hiveserver2:
    build:
      context: .
      dockerfile: ./services/hive/Dockerfile
      args:
        HIVE_VERSION: ${HIVE_VERSION}
        PG_JDBC_VERSION: ${PG_JDBC_VERSION}
    depends_on:
      - hive-metastore
      - resourcemanager
    container_name: hiveserver2
    hostname: hiveserver2
    command: ["hiveserver2"]
    networks:
      - bigdata-net
    ports:
      - "10000:10000"
      - "10002:10002"
    volumes:
      - ./configs/hive:/opt/hive/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop

  spark-client:
    build:
      context: .
      dockerfile: ./services/spark/Dockerfile
      args:
        SPARK_VERSION: ${SPARK_VERSION}
    depends_on:
      - hiveserver2
      - resourcemanager
      - hbase-master
      - base
    container_name: spark-client
    hostname: spark-client
    command: tail -f /dev/null
    tty: true
    stdin_open: true
    networks:
      - bigdata-net
    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop
      - ./configs/hive:/opt/hive/conf