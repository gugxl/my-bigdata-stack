# ~/my-bigdata-stack/docker-compose.yml (CORRECTED AGAIN)

# The 'version' attribute is obsolete, but harmless. You can remove this line if you want.
version: "3.8"

networks:
  bigdata-net:
    driver: bridge

volumes:
  hadoop_namenode_data:
  hadoop_datanode_data:
  hadoop_historyserver_data:
  hbase_data:
  postgres_metastore_data:
  zookeeper_data:
  zookeeper_log:

services:
  zookeeper:
    build:
      context: .
      dockerfile: ./services/zookeeper/Dockerfile # CORRECT PATH
      args:
        ZOOKEEPER_VERSION: ${ZOOKEEPER_VERSION}
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - bigdata-net
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/data
      - zookeeper_log:/datalog
    environment:
      ZOO_SERVER_ID: 1

  postgres-metastore:
    image: postgres:14
    container_name: postgres-metastore
    hostname: postgres-metastore
    networks:
      - bigdata-net
    ports:
      - "5432:5432"
    volumes:
      - postgres_metastore_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

  namenode:
    image: bigdata_hadoop-base # Give the base image a name for others to use
    build:
      context: .
      dockerfile: ./services/hadoop-base/Dockerfile # CORRECT PATH
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    container_name: namenode
    hostname: namenode
    networks:
      - bigdata-net
    command: ["hdfs", "namenode"]
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - ./configs/hadoop:/etc/hadoop
      - hadoop_namenode_data:/opt/hadoop/data/namenode
    environment:
      - HADOOP_USER_NAME=root
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  datanode:
    image: bigdata_hadoop-base # Use the same base image
    build:
      context: .
      dockerfile: ./services/hadoop-base/Dockerfile # CORRECT PATH
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    container_name: datanode
    hostname: datanode
    networks:
      - bigdata-net
    command: ["hdfs", "datanode"]
    depends_on:
      namenode:
        condition: service_healthy
    volumes:
      - ./configs/hadoop:/etc/hadoop
      - hadoop_datanode_data:/opt/hadoop/data/datanode

  resourcemanager:
    image: bigdata_hadoop-base # Use the same base image
    build:
      context: .
      dockerfile: ./services/hadoop-base/Dockerfile # CORRECT PATH
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    container_name: resourcemanager
    hostname: resourcemanager
    networks:
      - bigdata-net
    command: ["yarn", "resourcemanager"]
    depends_on:
      - namenode
      - datanode
    ports:
      - "8088:8088"
    volumes:
      - ./configs/hadoop:/etc/hadoop
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  nodemanager:
    image: bigdata_hadoop-base # Use the same base image
    build:
      context: .
      dockerfile: ./services/hadoop-base/Dockerfile # CORRECT PATH
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    container_name: nodemanager
    hostname: nodemanager
    networks:
      - bigdata-net
    command: ["yarn", "nodemanager"]
    depends_on:
      resourcemanager:
        condition: service_healthy
    volumes:
      - ./configs/hadoop:/etc/hadoop

  historyserver:
    image: bigdata_hadoop-base # Use the same base image
    build:
      context: .
      dockerfile: ./services/hadoop-base/Dockerfile # CORRECT PATH
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    container_name: historyserver
    hostname: historyserver
    networks:
      - bigdata-net
    command: ["mapred", "historyserver"]
    depends_on:
      - resourcemanager
    ports:
      - "19888:19888"
    volumes:
      - ./configs/hadoop:/etc/hadoop
      - hadoop_historyserver_data:/opt/hadoop/data/historyserver

  hbase-master:
    build:
      context: .
      dockerfile: ./services/hbase/Dockerfile # CORRECT PATH
      args:
        HBASE_VERSION: ${HBASE_VERSION}
    container_name: hbase-master
    hostname: hbase-master
    networks:
      - bigdata-net
    command: ["master", "start"]
    ports:
      - "16010:16010"
    volumes:
      - ./configs/hbase:/opt/hbase/conf
      - hbase_data:/data/hbase
    depends_on:
      - namenode
      - zookeeper

  hbase-regionserver:
    build:
      context: .
      dockerfile: ./services/hbase/Dockerfile # CORRECT PATH
      args:
        HBASE_VERSION: ${HBASE_VERSION}
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    networks:
      - bigdata-net
    command: ["regionserver", "start"]
    depends_on:
      - hbase-master

  hive-metastore:
    build:
      context: .
      dockerfile: ./services/hive/Dockerfile # CORRECT PATH
      args:
        HIVE_VERSION: ${HIVE_VERSION}
        PG_JDBC_VERSION: ${PG_JDBC_VERSION}
    container_name: hive-metastore
    hostname: hive-metastore
    networks:
      - bigdata-net
    command: ["metastore"]
    ports:
      - "9083:9083"
    volumes:
      - ./configs/hive:/opt/hive/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop # For HDFS access
    depends_on:
      - postgres-metastore
      - namenode

  hiveserver2:
    build:
      context: .
      dockerfile: ./services/hive/Dockerfile # CORRECT PATH
      args:
        HIVE_VERSION: ${HIVE_VERSION}
        PG_JDBC_VERSION: ${PG_JDBC_VERSION}
    container_name: hiveserver2
    hostname: hiveserver2
    networks:
      - bigdata-net
    command: ["hiveserver2"]
    ports:
      - "10000:10000"
      - "10002:10002"
    volumes:
      - ./configs/hive:/opt/hive/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop
    depends_on:
      - hive-metastore
      - resourcemanager

  spark-client:
    build:
      context: .
      dockerfile: ./services/spark/Dockerfile # CORRECT PATH
      args:
        SPARK_VERSION: ${SPARK_VERSION}
    container_name: spark-client
    hostname: spark-client
    networks:
      - bigdata-net
    command: tail -f /dev/null
    tty: true
    stdin_open: true
    volumes:
      - ./configs/spark:/opt/spark/conf
      - ./configs/hadoop:/opt/hadoop/etc/hadoop
      - ./configs/hive:/opt/hive/conf
    depends_on:
      - hiveserver2
      - resourcemanager
      - hbase-master