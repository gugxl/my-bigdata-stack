# 大数据 Docker 环境 验证手册

## 目录

1. [服务验证金字塔](#服务验证金字塔)
2. [第一层：基础协调与数据库服务](#第一层基础协调与数据库服务)
3. [第二层：核心存储 (HDFS)](#第二层核心存储-hdfs)
4. [第三层：资源调度 (YARN)](#第三层资源调度-yarn)
5. [第四层：应用层 (HBase, Hive)](#第四层应用层-hbase-hive)
6. [第五层：消息队列与流处理 (Kafka, Flink)](#第五层消息队列与流处理-kafka-flink)
7. [第六层：大数据计算 (Spark)](#第六层大数据计算-spark)
8. [第七层：任务调度与工作流 (Airflow)](#第七层任务调度与工作流-airflow)
9. [总结](#总结)

---

## 服务验证金字塔

验证顺序遵循依赖关系，从底层到上层：

```
      +-----------------+
      |      Spark      |  (依赖 YARN, HDFS, Hive, HBase)
      +-----------------+
      |       Hive      |  (依赖 YARN, HDFS, Metastore DB)
      +-----------------+
      |      HBase      |  (依赖 YARN, HDFS, ZooKeeper)
      +-----------------+
      |       YARN      |  (依赖 HDFS)
      +-----------------+
      |       HDFS      |
      +-----------------+
      |  Zookeeper & DB |  (独立基础服务)
      +-----------------+
```

---

## 第一层基础协调与数据库服务

### 1. `zookeeper`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps zookeeper
   ```

   状态应为 `Up`。

2. **日志检查**:

   ```bash
   docker compose logs zookeeper
   ```

    * 关键日志: `binding to port 0.0.0.0/0.0.0.0:2181`
    * 日志中不应有 `ERROR` 或 `Exception`。

3. **端口连接**:

   ```bash
   echo "ruok" | nc localhost 2181
   ```

    * 成功标志: 返回 `imok`。

### 2. `postgres-metastore`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps postgres-metastore
   ```

   状态应为 `Up`。

2. **日志检查**:

   ```bash
   docker compose logs postgres-metastore
   ```

    * 关键日志: `database system is ready to accept connections`

---

## 第二层核心存储 (HDFS)

### 1. `namenode`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps namenode
   ```

   状态应为 `Up (healthy)`。

2. **日志检查**:

   ```bash
   docker compose logs namenode
   ```

    * 首次启动日志: `STARTUP_MSG: Starting NameNode`, `successfully formatted`
    * 正常运行日志: `Serving GSSAPI ...`, `IPC Server handler ...`

3. **Web UI**: [http://localhost:9870](http://localhost:9870)

    * 成功标志: 可见 HDFS 管理界面，DataNode 活跃

### 2. `datanode`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps datanode
   ```

   状态应为 `Up`

2. **日志检查**:

   ```bash
   docker compose logs datanode
   ```

    * 关键日志: `STARTUP_MSG: Starting DataNode`, `Block pool ... registered with namenode`

3. **NameNode Web UI 确认**: [http://localhost:9870/dfshealth.html#tab-datanode](http://localhost:9870/dfshealth.html#tab-datanode)

    * 成功标志: 至少一个 "Live" DataNode，状态 "In Service"

---

## 第三层资源调度 (YARN)

### 1. `resourcemanager`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps resourcemanager
   ```

   状态应为 `Up (healthy)`

2. **日志检查**:

   ```bash
   docker compose logs resourcemanager
   ```

    * 关键日志: `STARTUP_MSG: Starting ResourceManager`, `Transitioned to active state`

3. **Web UI**: [http://localhost:8088](http://localhost:8088)

    * 成功标志: 节点列表、队列状态显示正常

### 2. `nodemanager`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps nodemanager
   ```

   状态应为 `Up`

2. **日志检查**:

   ```bash
   docker compose logs nodemanager
   ```

    * 关键日志: `STARTUP_MSG: Starting NodeManager`, `Registered with ResourceManager as nodemanager`

3. **Web UI**: [http://localhost:8088/cluster/nodes](http://localhost:8088/cluster/nodes)

    * 成功标志: 节点状态为 "RUNNING"

### 3. `historyserver`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps historyserver
   ```

   状态应为 `Up`

2. **日志检查**:

   ```bash
   docker compose logs historyserver
   ```

    * 关键日志: `STARTUP_MSG: Starting JobHistoryServer`, `JobHistoryServer metrics system started`

3. **Web UI**: [http://localhost:19888](http://localhost:19888)

    * 成功标志: JobHistory 界面可访问

---

## 第四层应用层 (HBase, Hive)

### 1. `hbase-master`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps hbase-master
   ```

   状态应为 `Up`

2. **日志检查**:

   ```bash
   docker compose logs hbase-master
   ```

    * 关键日志: `Master has completed initialization`

3. **Web UI**: [http://localhost:16010](http://localhost:16010)

    * 成功标志: RegionServer 活跃

### 2. `hive-metastore`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps hive-metastore
   ```

   状态应为 `Up`

2. **日志检查**:

   ```bash
   docker compose logs hive-metastore
   ```

    * 关键日志: `Starting Hive Metastore Server`, `Opened a connection to metastore`

### 3. `hiveserver2`

**验证步骤：**

1. **容器状态**:

   ```bash
   docker compose ps hiveserver2
   ```

   状态应为 `Up`

2. **日志检查**:

   ```bash
   docker compose logs hiveserver2
   ```

    * 关键日志: `Starting HiveServer2`, `HiveServer2 is started`

3. **Web UI**: [http://localhost:10002](http://localhost:10002)

---

## 第五层消息队列与流处理 (Kafka, Flink)

### 1. `kafka`

**验证步骤**：

1. **容器状态**:

   ```bash
   docker compose ps kafka
   ```

2. **日志检查**:

   ```bash
   docker compose logs kafka
   ```

    * 关键日志: `Kafka Server started`

3. **功能验证**:

   ```bash
   docker exec -it kafka kafka-topics.sh --bootstrap-server kafka:9092 --create --topic test-topic --partitions 1 --replication-factor 1
   docker exec -it kafka kafka-topics.sh --bootstrap-server kafka:9092 --list
   ```

### 2. `flink-jobmanager` & `flink-taskmanager`

**验证步骤**：

1. **容器状态**:

   ```bash
   docker compose ps flink-jobmanager
   docker compose ps flink-taskmanager
   ```

2. **日志检查**:

   ```bash
   docker compose logs flink-jobmanager
   docker compose logs flink-taskmanager
   ```

    * JobManager: `Starting Flink jobmanager process`
    * TaskManager: `Registered with JobManager`

3. **Web UI**: [http://localhost:8081](http://localhost:8081)

---

## 第六层大数据计算 (Spark)

### `spark-client`

**验证步骤**：

1. **容器状态**:

   ```bash
   docker compose ps spark-client
   ```
2. **进入容器**:

   ```bash
   docker exec -it spark-client bash
   ```
3. **启动 Spark Shell**:

   ```bash
   spark-shell
   sc.parallelize(1 to 10).sum()
   ```

---

## 第七层任务调度与工作流 (Airflow)

### 初始化 Airflow

```bash
docker compose up -d postgres-metastore
docker compose run --rm airflow-webserver bash -c "airflow db init && airflow users create --username admin --password your_password --firstname admin --lastname admin --role Admin --email admin@example.com"
```

### `airflow-webserver` & `airflow-scheduler`

1. **容器状态**:
   好的，我帮你把整个大数据 Docker 开发环境验证手册整理成一份**完整 Markdown 文件**，包含从底层到上层的服务验证步骤、命令、Web UI，以及 Airflow 初始化流程，方便直接操作。

```markdown
# 大数据开发环境验证手册（基于 Docker Compose）

本文档用于验证基于 Docker Compose 搭建的大数据开发环境，包括 Hadoop、Hive、HBase、Spark、Flink、Kafka、Airflow 等服务。验证顺序遵循**从底层到上层**的依赖顺序，确保每一层都正常运行后再进入下一层。

---

## 服务验证金字塔

```

```
  +-----------------+
  |      Spark      |  (依赖 YARN, HDFS, Hive, HBase)
  +-----------------+
  |       Hive      |  (依赖 YARN, HDFS, Metastore DB)
  +-----------------+
  |      HBase      |  (依赖 YARN, HDFS, ZooKeeper)
  +-----------------+
  |       YARN      |  (依赖 HDFS)
  +-----------------+
  |       HDFS      |
  +-----------------+
  |  Zookeeper & DB |  (独立基础服务)
  +-----------------+
```

````

---

## 第一层：基础协调与数据库服务

### 1. Zookeeper
- **容器状态**:
  ```bash
  docker compose ps zookeeper
````

状态应为 `Up`。

* **日志检查**:

  ```bash
  docker compose logs zookeeper
  ```

    * 关键日志: `binding to port 0.0.0.0/0.0.0.0:2181`
    * 不应出现 `ERROR` 或 `Exception`
* **端口连接测试**:

  ```bash
  echo "ruok" | nc localhost 2181
  ```

    * 返回 `imok` 表示服务正常。

### 2. PostgreSQL (Metastore)

* **容器状态**:

  ```bash
  docker compose ps postgres-metastore
  ```

  状态应为 `Up`。
* **日志检查**:

  ```bash
  docker compose logs postgres-metastore
  ```

    * 关键日志: `database system is ready to accept connections`

---

## 第二层：核心存储 (HDFS)

### 1. NameNode

* **容器状态**:

  ```bash
  docker compose ps namenode
  ```

  应显示 `Up (healthy)`
* **日志检查**:

  ```bash
  docker compose logs namenode
  ```

    * 首次启动: `STARTUP_MSG: Starting NameNode` 和 `successfully formatted`
    * 正常运行: 不应有 `ERROR` 或 `Exception`，寻找 `Serving GSSAPI ...` 和 `IPC Server handler ...`
* **Web UI**: [http://localhost:9870](http://localhost:9870)

    * 成功标志: HDFS 管理界面可访问，DataNode 状态正常

### 2. DataNode

* **容器状态**:

  ```bash
  docker compose ps datanode
  ```

  应显示 `Up`
* **日志检查**:

  ```bash
  docker compose logs datanode
  ```

    * 关键日志: `STARTUP_MSG: Starting DataNode` 或 `Block pool ... registered with namenode`
* **NameNode Web UI 确认**:
  [http://localhost:9870/dfshealth.html#tab-datanode](http://localhost:9870/dfshealth.html#tab-datanode)

---

## 第三层：资源调度 (YARN)

### 1. ResourceManager

* **容器状态**:

  ```bash
  docker compose ps resourcemanager
  ```

  状态应为 `Up (healthy)`
* **日志检查**:

  ```bash
  docker compose logs resourcemanager
  ```

    * 关键日志: `STARTUP_MSG: Starting ResourceManager` 和 `Transitioned to active state`
* **Web UI**: [http://localhost:8088](http://localhost:8088)

### 2. NodeManager

* **容器状态**:

  ```bash
  docker compose ps nodemanager
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs nodemanager
  ```

    * 关键日志: `Registered with ResourceManager as nodemanager`
* **ResourceManager Web UI 确认**: [http://localhost:8088/cluster/nodes](http://localhost:8088/cluster/nodes)

### 3. HistoryServer

* **容器状态**:

  ```bash
  docker compose ps historyserver
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs historyserver
  ```

    * 关键日志: `JobHistoryServer metrics system started`
* **Web UI**: [http://localhost:19888](http://localhost:19888)

---

## 第四层：应用存储层 (HBase, Hive)

### 1. HBase Master

* **容器状态**:

  ```bash
  docker compose ps hbase-master
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs hbase-master
  ```

    * 关键日志: `Master has completed initialization`
* **Web UI**: [http://localhost:16010](http://localhost:16010)

### 2. Hive Metastore

* **容器状态**:

  ```bash
  docker compose ps hive-metastore
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs hive-metastore
  ```

    * 关键日志: `Starting Hive Metastore Server` 和 `Opened a connection to metastore`

### 3. HiveServer2

* **容器状态**:

  ```bash
  docker compose ps hiveserver2
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs hiveserver2
  ```

    * 关键日志: `HiveServer2 is started`
* **Web UI**: [http://localhost:10002](http://localhost:10002)

---

## 第五层：消息队列与流处理 (Kafka, Flink)

### 1. Kafka

* **容器状态**:

  ```bash
  docker compose ps kafka
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs kafka
  ```

    * 关键日志: `Kafka Server started`
* **功能验证**:

  ```bash
  docker exec -it kafka kafka-topics.sh --bootstrap-server kafka:9092 --create --topic test-topic --partitions 1 --replication-factor 1
  docker exec -it kafka kafka-topics.sh --bootstrap-server kafka:9092 --list
  ```

### 2. Flink

* **容器状态**:

  ```bash
  docker compose ps flink-jobmanager
  docker compose ps flink-taskmanager
  ```

  状态应为 `Up`
* **日志检查**:

  ```bash
  docker compose logs flink-jobmanager
  docker compose logs flink-taskmanager
  ```

    * JobManager 日志: `Starting Flink jobmanager process`
    * TaskManager 日志: `Registered with JobManager`
* **Web UI**: [http://localhost:8081](http://localhost:8081)

---

## 第六层：计算层 (Spark)

### Spark Client

* **容器状态**:

  ```bash
  docker compose ps spark-client
  ```

  状态应为 `Up`
* **进入容器**:

  ```bash
  docker exec -it spark-client bash
  ```
* **Spark Shell 测试**:

  ```scala
  spark-shell
  sc.parallelize(1 to 10).sum()
  ```

---

## 第七层：任务调度与工作流 (Airflow)

### 1. 初始化数据库与管理员账号

```bash
docker compose up -d postgres-metastore
docker compose run --rm airflow-webserver bash -c "airflow db init && airflow users create --username admin --password your_password --firstname admin --lastname admin --role Admin --email admin@example.com"
```

### 2. Airflow 容器状态

```bash
docker compose ps airflow-webserver
docker compose ps airflow-scheduler
```

### 3. Web UI 验证

* 访问 [http://localhost:8080](http://localhost:8080)
* 使用管理员账号登录
* 启动 DAG 并观察调度是否正常

---

## 清理

```bash
docker compose down --volumes --remove-orphans
docker compose --profile build down --volumes
docker rmi -f $(docker images -q bigdata-hadoop-base)
docker rmi -f $(docker images -q bigdata-hive)
docker rmi -f $(docker images -q bigdata-hbase)
docker rmi -f $(docker images -q bigdata-spark)
docker rmi -f $(docker images -q my-bigdata-base)
```

---

## 总结

1. **验证顺序**：从底层到上层逐层验证。
2. **关键检查点**：容器状态、日志输出、Web UI 或命令功能。
3. **问题定位**：一层未通过，不进入下一层，快速定位问题。
4. **Airflow 初始化**：确保管理员账号已创建，并完成数据库初始化。


