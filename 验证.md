非常好的提议！这种逐个击破、逐层验证的思路是排查分布式系统问题的最佳实践。它能确保我们每一步都建立在坚实可靠的基础之上。

我们将按照服务依赖的**从底层到上层**的顺序进行验证。每验证通过一个，我们才进入下一个。

---

### 服务验证金字塔

我们的验证顺序将遵循以下金字塔结构，从下往上：

```
      +-----------------+
      |      Spark      |  (依赖 YARN, HDFS, Hive, HBase)
      +-----------------+
      |       Hive      |  (依赖 YARN, HDFS, Metastore DB)
      +-----------------+
      |      HBase      |  (依赖 YARN, HDFS, ZooKeeper)
      +-----------------+
      |       YARN      |  (依赖 HDFS)
      +-----------------+
      |       HDFS      |
      +-----------------+
      |  Zookeeper & DB |  (独立基础服务)
      +-----------------+
```

### 第一层：基础协调与数据库服务

这两个服务是最底层的，不依赖我们集群中的其他任何组件。

#### 1. `zookeeper`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps zookeeper`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs zookeeper`。
        *   **关键日志**: 寻找 `binding to port 0.0.0.0/0.0.0.0:2181`。这表示它成功监听了 2181 端口。日志中**不应有**任何 `ERROR` 或 `Exception`。
    3.  **端口连接 (最可靠)**: 从你的 WSL2 终端执行：
        ```bash
        echo "ruok" | nc localhost 2181
        ```
        *   **成功标志**: 如果返回 `imok`，则表示 ZooKeeper 服务完全正常。

#### 2. `postgres-metastore`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps postgres-metastore`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs postgres-metastore`。
        *   **关键日志**: 寻找 `database system is ready to accept connections`。这表示数据库已成功启动并准备好服务。

---

### 第二层：核心存储 (HDFS)

HDFS 是整个大数据生态的基石。它由 `namenode` 和 `datanode` 组成。

#### 1. `namenode`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps namenode`，状态应为 `Up (healthy)`。我们在 `docker-compose.yml` 中为它配置了健康检查，所以 `healthy` 状态是最好的证明。
    2.  **日志检查**: `docker-compose logs namenode`。
        *   **首次启动**: 会有 `STARTUP_MSG: Starting NameNode` 和 `successfully formatted` 的日志。
        *   **正常运行**: 日志会不断刷新，但不应有 `ERROR` 或 `Exception`。寻找 `Serving GSSAPI ...` 和 `IPC Server handler ...` 等信息。
    3.  **Web UI (最直观)**: 在浏览器中访问 **[http://localhost:9870](http://localhost:9870)**。
        *   **成功标志**: 你能看到 HDFS 的管理界面。在 "Datanodes" 标签页下，你应该能看到活动的 DataNode。

#### 2. `datanode`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps datanode`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs datanode`。
        *   **关键日志**: 寻找 `STARTUP_MSG: Starting DataNode` 和 `Successfully connected to namenode` 或 `Block pool ... registered with namenode`。这表示它成功注册到了 NameNode。
    3.  **NameNode Web UI 确认**: 再次访问 **[http://localhost:9870/dfshealth.html#tab-datanode](http://localhost:9870/dfshealth.html#tab-datanode)**。
        *   **成功标志**: 你能看到至少一个 "Live" 的 DataNode，并且它的状态是 "In Service"。

---

### 第三层：资源调度 (YARN)

YARN 负责集群的资源管理和任务调度，由 `resourcemanager`, `nodemanager`, `historyserver` 组成。

#### 1. `resourcemanager`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps resourcemanager`，状态应为 `Up (healthy)`。
    2.  **日志检查**: `docker-compose logs resourcemanager`。
        *   **关键日志**: 寻找 `STARTUP_MSG: Starting ResourceManager` 和 `Transitioned to active state`。这表示它已成功成为主节点。日志中**不应再有**关于队列初始化失败的错误。
    3.  **Web UI (最直观)**: 在浏览器中访问 **[http://localhost:8088](http://localhost:8088)**。
        *   **成功标志**: 你能看到 YARN 的管理界面。在 "Nodes" 标签页下，你应该能看到活动的 NodeManager。在 "Scheduler" 菜单下，你应该能看到我们配置的 `root.default` 队列。

#### 2. `nodemanager`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps nodemanager`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs nodemanager`。
        *   **关键日志**: 寻找 `STARTUP_MSG: Starting NodeManager` 和 `Registered with ResourceManager at resourcemanager`。这表示它成功注册到了 ResourceManager。
    3.  **ResourceManager Web UI 确认**: 访问 **[http://localhost:8088/cluster/nodes](http://localhost:8088/cluster/nodes)**。
        *   **成功标志**: 你能看到至少一个状态为 "RUNNING" 的节点。

#### 3. `historyserver`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps historyserver`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs historyserver`。
        *   **关键日志**: 寻找 `STARTUP_MSG: Starting JobHistoryServer` 和 `Jetty embedded server started`。
    3.  **Web UI (最直观)**: 在浏览器中访问 **[http://localhost:19888](http://localhost:19888)**。
        *   **成功标志**: 你能看到 "JobHistory" 的界面，即使里面没有任何作业记录。

---

### 第四层及以上：应用层 (HBase, Hive, Spark)

在验证这些服务之前，请确保 **HDFS 和 YARN** 都已完全正常。

#### `hbase-master`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps hbase-master`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs hbase-master`。
        *   **关键日志**: 寻找 `Master has completed initialization`。
    3.  **Web UI (最直观)**: 访问 **[http://localhost:16010](http://localhost:16010)**。
        *   **成功标志**: 你能看到 HBase Master 的 UI，并且在 "Region Servers" 部分能看到活动的 RegionServer。

#### `hive-metastore`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps hive-metastore`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs hive-metastore`。
        *   **关键日志**: 寻找 `Starting Hive Metastore Server` 和 `Opened a connection to metastore`。并且，**不应有**连接 `postgres-metastore` 失败的错误。首次启动会有 `schemaTool` 相关的日志。

#### `hiveserver2`
*   **如何验证**:
    1.  **容器状态**: `docker-compose ps hiveserver2`，状态应为 `Up`。
    2.  **日志检查**: `docker-compose logs hiveserver2`。
        *   **关键日志**: 寻找 `Starting HiveServer2` 和 `HiveServer2 is started`。
    3.  **Web UI**: 访问 **[http://localhost:10002](http://localhost:10002)**。
        *   **成功标志**: 你能看到 HiveServer2 的 Web UI。

---

现在，请按照这个清单，从底向上，**首先解决 `resourcemanager` 的问题**。修复并确认它在 Web UI 上正常工作后，我们再按顺序检查 `nodemanager`, `historyserver`, `hive-metastore`, `hiveserver2` 等服务。如果遇到问题，请将对应服务的日志发给我。